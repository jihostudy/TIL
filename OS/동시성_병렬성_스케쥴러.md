<a href="https://vivid-chamomile-2f5.notion.site/Lecture8-192d85adc2df809d8e38d264e4692cab?pvs=4">정리 파일 링크</a>

## 동시성 (Concurrency)

정의: CPU 내에서 여러 개의 프로세스를 빠르게 전환하여 마치 작업이 동시에 실행되는 것처럼 보이는 것

- 실제로는 동시에 실행되지 않는다 → 동시에 실행 : 병렬성

동시성을 사용하면 (장점)

1. CPU가 대기 상태로 머무르지 않고 연속적으로 작업을 처리할 수 있다.
2. 다양한 프로세스 (작업)을 동시에 실행하는 것처럼 보여, 사용자 경험이 좋다

동시성은 스케쥴러에 의해 실행된다.

스케쥴러는 작업 분할 → 시간 할당 (작업 실행) → 작업 재할당 (컨텍스트 스위칭) 과정을 통해 프로세스 (작업, 스레드)를 메모리에 할당한다.

> 스케쥴러 알고리즘은 다양한 알고리즘이 있으며 CPU는 스케쥴링 알고리즘에 따라 스케쥴링한다.
> 

<aside>
👉🏻

스케쥴링 알고리즘에는 어떤 것들이 있나요?

보통, Preemption 여부 (실행중인 프로세스, 스레드를 중간에 실행중지하고 다른 작업을 실행시키는 방법)와 스케쥴링 데이터의 기준 (도착 시간, 할당된 시간, 우선순위)에 따라 알고리즘이 다양하다.

- FIFO
- Round-Robin
- SPN (Shortest Path Next)
- SRTN (Shortest Remaining Time Next)
- HRRN (High Response Ratio Next)
- Priority
- MLQ (Multi Level Queue)
</aside>

<aside>
👉🏻

자바스크립트의 이벤트 루프는 동시성을 지원하는 예제인가요?

네 맞습니다.

이벤트 루프는 콜 스택 (Call Stack), 이벤트 큐를 토대로 동시성 과정을 구현하였으며 스케쥴링을 수행합니다.

이 과정은 다음과 같이 이루어집니다

1. 콜 스택이 비어 있는지 확인합니다.
2. 콜 스택이 비어 있다면, 이벤트 큐에서 대기 중인 첫 번째 콜백 함수를 가져와 콜 스택에 추가합니다.
3. 콜백 함수가 실행되고, 실행이 완료되면 콜 스택에서 제거됩니다.
4. 이 과정을 반복합니다.

```jsx
console.log("Start");

setTimeout(() => {
    console.log("Timeout 1");
}, 0);

setTimeout(() => {
    console.log("Timeout 2");
}, 0);

console.log("End");

// 결과
Start (콜 스택)
End (콜 스택)
Timeout 1 (이벤트 큐)
Timeout 2 (이벤트 큐)
```

</aside>

### Thread Pool (스레드 풀)

서버 응용 프로그램을 이러한 요청을 처리하는 방식은 요청이 도착할 때마다 새 스레드를 만들고 새로 만든 스레드에서 받은 요청을 처리한다.

이러한 방식은 구현이 간단해 보이지만 큰 단점이 있다.

→ 모든 요청에 대해 새 스레드를 생성하는 서버는 실제 요청을 처리하는 것보다 스레드 생성 및 소멸에 더 많은 시간을 소비하고 더 많은 시스템 리소스를 소비합니다.

→ 스레드를 생성하고 사용하는 것은 운영체제의 자원을 사용하는 것으로, 너무 많은 스레드가 생성되면 서버가 다운될 수 있다.

따라서 Thread Pool을 사용합니다.

- JVM의 Heap 메모리 영역에 저장된다.
- 각 스레드는 스택 메모리(Stack Memory)를 사용하여 자신의 실행 컨텍스트(변수, 메서드 호출 등)를 관리

**[사용하는 이유]**

“미리 일정 개수의 쓰레드를 생성하여 관리하는 기법”

이렇게 생성된 쓰레드들은 작업을 할당받기 위해 대기 상태에 있게 되는데, 작업이 발생하면 대기 중인 쓰레드 중 하나를 선택하여 작업을 수행합니다. 

작업이 완료되면 해당 스레드는 다시 대기 상태로 돌아가고, 새로운 작업을 할당받을 준비를 합니다.

쓰레드 풀을 사용하면 스레드 생성 및 삭제에 따른 오버헤드를 줄일 수 있으며, 특정 시점에 동시에 처리할 수 있는 작업의 개수를 제한할 수 있습니다. 

이를 통해 시스템의 자원을 효율적으로 관리하고 성능을 향상시킬 수 있습니다.

[작동 방식]

1. 작업 제출: 클라이언트는 스레드 풀에 작업을 제출합니다. 이 작업은 Runnable 또는 Callable 인터페이스를 구현한 객체이다.
2. 작업 대기: 제출된 작업은 대기 큐에 저장됩니다. 만약 현재 실행 중인 스레드 수가 코어 스레드 수보다 적으면, 새로운 스레드가 생성되어 작업을 실행합니다.
3. 스레드 재사용: 작업이 완료된 스레드는 종료되지 않고, 다음 작업을 위해 대기 상태로 유지됩니다. 이를 통해 스레드 생성 비용을 줄입니다.
4. 스레드 종료: 스레드 풀의 설정에 따라, 일정 시간 동안 사용되지 않은 스레드는 종료될 수 있습니다.

<aside>
👉🏻

스레드풀을 사용하는 이유와 장단점에 대해서 설명해주세요

새로운 요청마다 스레드를 새성하게 되면 너무 많은 스레드를 생성하여 시스템 리소스를 낭비하므로, 스레드를 관리하기 위해 사용합니다.

스레드 풀을 사용하면 스레드 생성 및 삭제에 따른 오버헤드를 줄일 수 있으며, 특정 시점에 동시에 처리할 수 있는 작업의 개수를 제한할 수 있습니다. 

스레드 풀도 적절한 관리가 되지 않으면 독점 현상, 데드락 등 다양한 오류를 발생시킬 수 있습니다.

</aside>

## 스케쥴러

정의: 운영체제의 핵심 구성 요소로, CPU와 같은 시스템 자원을 적절히 분배하기 위해 프로세스나 스레드의 실행 순서를 관리하는 역할

주로 컨텍스트 스위칭을 하는 역할이다.

[작동 방식]

1. 작업 대기열 관리
2. 우선순위 설정 (스케쥴링 알고리즘 마다 상이)
3. 우선순위 결정 (스케쥴링 알고리즘 토대)
4. 자원 분배
5. 완료 및 자원 해제

<aside>
👉🏻

컨텍스트 스위칭(Context Switching)

CPU가 현재 실행 중인 작업(프로세스 또는 스레드)의 상태를 저장하고, 새로운 작업의 상태를 불러와 실행을 전환하는 과정을 의미합니다.

</aside>

<aside>
👉🏻

컨텍스트 스위칭이 발생할 때 생기는 부정적인 영향에 대해서 설명해주세요

컨텍스트 스위칭 과정은 시간적 비용이 가장 큰 쟁점입니다.

크게 Context Saving → Context Restoring → Context Switching 과정으로 수행되어서, 컴퓨터공학적으로 시간이 오래 걸리는 작업입니다.

</aside>

<aside>
👉🏻

(선택)프로세스 스케쥴링과 스레드 스케쥴링의 차이점에 대해서 설명해주세요.

프로세스 컨텍스트 스위칭과 스레드 컨텍스트 스위칭중 어떤 것이 더 오래 걸리는 작업일까요?

프로세스 컨텍스트 스위칭이 더 오래걸립니다.

프로세스의 컨텍스트 스위칭 과정은 크게 지금까지 작업한 내용을 저장 + Flush을 통한 메모리 초기화 작업으로 정리됩니다.

이때, Flush를 하는 이유는 새로 실행되는 프로세스가 기존에 실행되는 프로세스의 메모리 주소 공간에 침범하면 안 되기 때문입니다.

반면, 스레드는 메모리 주소 공간을 공유하기 때문에 Flush 하는 작업을 수행하지 않아도 됩니다.

따라서, 지금까지 작업한 내용을 저장하는 작업만 수행합니다.

</aside>

<aside>
👉🏻

컨텍스트 스위칭 과정에서 프로세스 / 스레드의 정보는 어디에 저장할까요?

프로세스는 PCB (Process Control Block), 스레드는 TCB (Thread Control Block)의 자료구조 형식에 저장합니다.

각 구조가 어떻게 생겼는지는 자세히 알 필요는 없다고 생각하지만,

해당 구조에는 

- 프로세스의 경우 pid, 스레드의 경우 tid
- 스케쥴링 과정에서 사용하는 우선순위 값 (없을 수도)
- PC (Program Counter)
- 각종 레지스터 및 메모리 관련 정보

등이 저장되어 있으며, 크기는 PCB > TCB 입니다.

</aside>

## 병렬성 (Parallelism)

정의: 다중 코어 CPU 또는 다중 프로세서를 활용하여 여러 작업을 물리적으로 동시에 실행하는 기술

- 작업이 실제로 동시에 이루어지는 기술이며, 이를 구현하기 위해서는 추가 하드웨어가 필요합니다.
- 실시간 처리 / 대규모 처리 작업에 용이합니다.

[작동 방식]

1. 작업 분할
2. 자원 할당
3. 병렬 실행
4. 결과 통합
5. 오류 복구 및 관리

<aside>
👉🏻

동시성과 병렬성의 차이에 대해 알려주세요

동시성은 하나의 CPU에서 여러가지 프로세스/스레드를 빠르게 Context Switching하며 실행하는 것을 의미하며, 

병렬성은 여러 개의 CPU에서 실제로 여러가지 프로세스/스레드를 동시에 실행하는 것입니다.

</aside>

## 키워드

<aside>
👉🏻

(선택) 콘보이 현상

하나의 프로세스/스레드가 CPU를 독점하는 현상을 의미합니다.

스케쥴링 기법을 통해 적절하게 분배해야 합니다.

단, 실제로 CPU를 많이(계속) 할당해야 하는 작업에게 평등을 근거로 CPU를 할당하지 않으면 안됩니다 (게임)

</aside>

<aside>
👉🏻

(선택) 선점형 /  비선점형 스케쥴링

Preemptive, Non-Preemptive이라고 하며,

선점형 (Preemptive) 스케쥴링은 강제로 CPU 사용을 빼앗는 스케쥴링입니다. (”Preemption 한다”고 표현)

- 컨텍스트 스위칭을 자주 해야 해서 Context Switching Overhead가 크다
- 보통 작업마다 할당된 시간 (Time Quantam)이 존재하여, 해당 시간이 지나면 Preempt 됩니다.

반면에, 비선점형(Non-Preemptive) 스케쥴링은 하나의 프로세스/스레드가 할당되면 끝날 때까지 CPU를 사용하도록 하는 스케쥴링 기법입니다.

- 비선점형 스케쥴링은 작업의 우선순위가 역전되는 Priority Inversion 현상이 발생할 수 있습니다.
    - Priority Inversion: 우선순위가 낮은 작업이 먼저 들어왔다는 이유로 우선순위가 높은 작업보다 우선적으로 실행되는 현상
</aside>

<aside>
👉🏻

라운드로빈 스케쥴링

- 작업 실행 시간 (Arrival Time)을 기준으로 스케쥴링
- 선점형 (Preemptive) 스케쥴링
- 작업이 실행된 순서대로 실행되며, 할당된 시간 (time quantam)이 초과되면 Ready Queue (스케줄러가 관리하는 작업의 대기 공간)의 맨뒤로 이동합니다.

만약, 할당된 시간이 너무 적으면 → n개의 프로세스가 1/n 만큼씩 CPU를 사용하는 Processor Sharing 현상이 발생할 수 있다.

반대로, 할당된 시간이 너무 크면 → 선점형 스케쥴링보다는 비선점형 스케쥴링처럼 실행될 수 있다.

따라서, 적절한 Time Quantam을 설정해주어야 한다.

</aside>

<aside>
👉🏻

(선택) 암달의 법칙

어떤 작업의 병렬 처리 성능 향상이 전체 프로그램 실행 시간에 미치는 영향을 수학적으로 모델링한 것

![image.png](attachment:5bab3373-939d-4534-9cf8-24ed33441e56:image.png)

- S(N): N개의 프로세서를 사용할 때의 속도 향상 비율 (Speedup)
- P: 병렬 처리할 수 있는 비율
- 1−P: 병렬화가 불가능한(순차적으로 실행해야 하는) 비율
- N: 사용하는 프로세서(코어) 개수

### **암달의 법칙이 의미하는 것**

- 병렬 처리할 수 없는 부분(1-P, 순차 실행 부분)이 전체 실행 시간에서 차지하는 비율이 높을수록, 병렬 성능 향상의 효과가 제한된다.
    - 병렬 처리할 수 없는 부분을 최소화해라.
- 프로세서 개수(N)를 계속 늘려도 순차 실행 비율(1-P)이 존재하는 한 무한한 성능 향상을 얻을 수 없다.
    - 프로세스 개수를 막 늘린 필요는 없다.
- 병렬화가 가능한 부분(P)이 작다면, 아무리 많은 CPU 코어를 추가하더라도 성능 향상은 미미하다.
    - 병렬화 가능한 부분 (P)를 크게, 불가능한 부분(1-P)를 작게 만들어라.
</aside>

<aside>
👉🏻

(선택) c10k 문제

단일 서버에서 동시에 10,000개 이상의 클라이언트 연결을 효율적으로 처리하는 문제를 의미한다.

→ 운영 체제의 네트워크 처리 방식과 멀티스레딩 모델의 한계로 인해 발생

당시에는

1. 하나의 쓰레드(Thread) 또는 프로세스(Process)를 생성하여 → **컨텍스트 스위칭(Context Switching)** 비용이 증가하여 성능이 급격히 저하
    - 메모리 및 CPU 사용량도 증가한다.
2. 네트워크 프로그래밍은 대부분 **Blocking I/O**를 사용 → 하나의 요청이 데이터 수신을 기다리는 동안 다른 작업을 수행할 수 없어 성능이 저하
3. 전통적인 **select() / poll()** 같은 소켓 처리 방식은  모든 연결을 반복 검사(Polling)하기 때문에 연결 수가 많아지면 성능이 저하됨

해결된 방법

1. 비동기 / 이벤트 기반 모델 
2. 논블로킹 I/O로의 전환
3. 멀티코어 분산 시스템 활동
    - 리버스 프록시 : nginx, HAProxy
    - MSA 서비스
    - 쿠버네티스
4. 소켓 프로그래밍에는 새로운 네트워크 통신 프로토콜 개발
</aside>
